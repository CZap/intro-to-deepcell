{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yesterday, we gave a brief overview of Python and three powerful libraries we will be using to develop for DeepCell. Today, we will become more familiar with SciPy and in particular the `scikit-image` library as we review the basics of image processing using Python. <i> NB: scikit-image has a description of tag `skimage` that can be used interchageably with the offical name.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will cover:\n",
    "\n",
    "* Loading & Handling Image Data: Input/output, Data Types, and Colorspaces\n",
    "* Preprocessing: Contrast Adjustment\n",
    "* Thresholding\n",
    "* Filtering, Edge Detection, and Convolutions\n",
    "* Morphological Operations: Structuring Elements and the Watershed Transform\n",
    "* Affine Transformations\n",
    "* Writing Output to Files: Images, JSON, and NPZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Handling Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skimage` has a number of useful functions we can import to load and manipulate images, as well as save the resulting images. Remember, though, this library builds on NumPy, so we will need to import that library as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize as imresize\n",
    "\n",
    "# Read an JPEG image into a numpy array\n",
    "#img = imread('resources/img_000000000_Phase_000.png')\n",
    "img = imread('resources/cat.jpg')\n",
    "print(img.dtype, img.shape)  # Prints \"uint8 (400, 248, 3)\"\n",
    "\n",
    "# We can tint the image by scaling each of the color channels\n",
    "# by a different scalar constant. The image has shape (400, 248, 3);\n",
    "# we multiply it by the array [1, 0.95, 0.9] of shape (3,);\n",
    "# numpy broadcasting means that this leaves the red channel unchanged,\n",
    "# and multiplies the green and blue channels by 0.95 and 0.9\n",
    "# respectively.\n",
    "img_tinted = img * [1, 0.95, 0.9]\n",
    "\n",
    "# Resize the tinted image to be 300 by 300 pixels.\n",
    "img_tinted = imresize(img_tinted, (300, 300))\n",
    "\n",
    "# Write the tinted image back to disk\n",
    "imsave('resources/cat_tinted.jpg', np.uint8(img_tinted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than \"hardcoding\" the file path, a more robust way of handling these operations is to designate a section of code to specify the directory path and file name as variables. \n",
    "\n",
    "If the file is not in the current working directory, you must also have a way of specifying the path to the directory where the file is stored. In our case, the example images are stored in the directory called 'resources' in the same folder as this notebook. Note that you can use either the full path - something like r\"/home/user/bootcamp/intro-to-deepcell/resources/example_cells_1.tif\" or the relative path, starting from the current working directory.\n",
    "\n",
    "NB: Paths and filenames can contain slashes, empty spaces and other special symbols, which can cause trouble for programming languages under certain circumstances. To circumvent such trouble, add the letter r before your string definition to create a so-called 'raw string', which is not affected by these problems (e.g. `my_raw_string = r\"some string with funny symbols: \\\\\\!/~***!\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string variable with the name of the file you'd like to load (here: 'example_cells_1.tif').\n",
    "# Suggested name for the variable: filename\n",
    "filename = r'img_000000000_Far-red_001.png'\n",
    "\n",
    "# Create a string variable with the path to the directory that contains the file you'd like to load.\n",
    "# Suggested name for the variable: dirpath\n",
    "dirpath = r'resources'  # Relative path\n",
    "#dirpath = r'/home/user/bootcamp/intro-to-deepcell/resources/img_000000000_Far-red_001.png'  # Absolute path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now combine the directory path and file name into one variable, the file path\n",
    "\n",
    "# Import the function 'join' from the module 'os.path'\n",
    "# This function automatically takes care of the slashes that need to be added when combining two paths.\n",
    "from os.path import join\n",
    "\n",
    "# Print the result to see that everything is correct\n",
    "# Suggested name for the variable: filepath\n",
    "filepath = join(dirpath, filename)\n",
    "print(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the file path established, we can load the image (using the `imread` function we imported earlier), make sure the load was successful, and display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 'img_000000000_Far-red_001.png' and store it in a variable.\n",
    "# Suggested name for the variable: img\n",
    "img = imread(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the load went as expected\n",
    "\n",
    "# Check that 'img' is a variable of type 'ndarray' - use Python's built-in function 'type'.\n",
    "print(\"Loaded array is of type:\", type(img))\n",
    "\n",
    "# Print the shape of the array using the numpy-function 'shape'. \n",
    "print(\"Loaded array has shape:\", img.shape)\n",
    "\n",
    "# Check the datatype of the individual numbers in the array. You can use the array attribute 'dtype' to do so.\n",
    "print(\"Loaded values are of type:\", img.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: The dtype should be 'uint16', because these are unsigned 16-bit integer images. Another common dtype for images is uint8. You can read more about the differences [here](https://www.mathworks.com/help/matlab/creating_plots/working-with-8-bit-and-16-bit-images.html) and [here](https://printaura.com/8-bit-vs-16-bit-images-whats-the-difference-which-to-use/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to take a look at images. To plot the array as an image, use pyplot's functions `plt.imshow` followed by `plt.show`. \n",
    "\n",
    "You can check the documentation for `plt.imshow` and note the parameters that can be specified, such as colormap (cmap)\n",
    "and interpolation. Since we are working with scientific data, interpolation is unwelcome, so you should set it to \"none\". The most common cmap for grayscale images is naturally \"gray\". You may also want to adjust the size of the figure. You can do this by preparing the figure canvas with the function `plt.figure` before calling `plt.imshow`. The canvas size is adjusted using the keyword argument 'figsize' when calling `plt.figure`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(img, interpolation='none', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry if it's dark, we'll fix that in a minute. In the meantime, for our peace of mind, here is a side-by-sdie example using our cat image from ealier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = imread('resources/cat.jpg')\n",
    "img_tinted2 = img2 * [1, 0.95, 0.9]\n",
    "\n",
    "# Show the original image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img2)\n",
    "\n",
    "# Show the tinted image\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# A slight gotcha with imshow is that it might give strange results if presented with data that is not uint8. \n",
    "# To work around this, we explicitly cast the image to uint8 before displaying it.\n",
    "plt.imshow(np.uint8(img_tinted2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw microscope images, like the ones we will be using to train our neural nets, often start out looking like garbage. Viz.:\n",
    "![alt text][phase000]\n",
    "\n",
    "[phase000]: ./resources/img_000000000_Phase_000.png \"A Bunch of Cells?\"\n",
    "\n",
    "Before we can really use this image for anything, we need to improve it. This is the (pre)process of preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common preprocessing operation is to tweak the image's contrast.\n",
    "\n",
    "Within `skimage`, there are multiple functions inside the `skimage.exposure` module that relate to contrast adjustment. We will highlight a few of them here:\n",
    "\n",
    "* `skimage.exposure.histogram`\n",
    "* `skimage.exposure.equalize_hist`\n",
    "* `skimage.exposure.equalize_adapthist`\n",
    "* `skimage.exposure.rescale_intensity`\n",
    "* `skimage.exposure.adjust_gamma`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `skimage.exposure.histogram`\n",
    "\n",
    "Let's use `skimage.exposure.histogram` to view the distribution of pixel intensities in cat image.\n",
    "\n",
    "Note the use of indices on the cat image. It's often most informative to look at each channel in a color image separately, which is what we're doing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import histogram\n",
    "\n",
    "# compute histogram in Red channel of cat image\n",
    "(counts, bins) = histogram(img2[:,:,0])\n",
    "# view histogram\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(bins,counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very cool.\n",
    "\n",
    "Now, let's look at our cell image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute histogram\n",
    "phase_image = imread(\"resources/img_000000000_Phase_000.png\")\n",
    "(counts, bins) = histogram(phase_image)\n",
    "# view histogram\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter( bins, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What...?\n",
    "\n",
    "Why is this histogram different from the previous one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### skimage.exposure.equalize_hist\n",
    "\n",
    "Let's use `skimage.exposure.equalize_hist` to change the histogram of the phase_image. This function changes the pixel intensity values in the image by spreading them out as evenly as possible across the pixel intensity range while still preserving relative intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import equalize_hist\n",
    "\n",
    "# compute histogram\n",
    "equalized_image = equalize_hist(phase_image)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16,8]\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(equalized_image, cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(phase_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare these two images' histograms side by side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute histograms\n",
    "(counts_phase, bins_phase) = histogram(phase_image)\n",
    "(counts_equalized, bins_equalized) = histogram(equalized_image)\n",
    "# view histograms\n",
    "plt.rcParams['figure.figsize'] = [10,5]\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(bins_phase,counts_phase)\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(bins_equalized,counts_equalized)\n",
    "(equalized_image.dtype, equalized_image.min(), equalized_image.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the distribution of the pixels has been dramatically transformed! Not only have we moved from a uint16 pixel encoding to some sort of float encoding (probably float64), but we've also redistributed our pixels so that they are spread all across the available pixel value range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute histograms\n",
    "(counts_phase, bins_phase) = histogram(phase_image)\n",
    "(counts_equalized, bins_equalized) = histogram(equalized_image)\n",
    "\n",
    "# compute cumulative distribution functions\n",
    "img_cdf_phase, bins_phase = exposure.cumulative_distribution(phase_image, 256)\n",
    "img_cdf_phase = img_cdf_phase\n",
    "img_cdf_equalized, bins_equalized = exposure.cumulative_distribution(equalized_image, 256)\n",
    "img_cdf_equalized = img_cdf_equalized\n",
    "\n",
    "# view histograms\n",
    "fig, axes = plt.subplots( nrows=1, ncols=2, figsize=(16,8) )\n",
    "\n",
    "## left plot\n",
    "right_y_axis_0 = axes[0].twinx()\n",
    "axes[0].scatter(bins_phase,counts_phase)\n",
    "#axes[0].plot(bins_phase, img_cdf_phase, 'r')\n",
    "right_y_axis_0.set_ylim(0,1)\n",
    "right_y_axis_0.plot(bins_phase, img_cdf_phase, 'r')\n",
    "\n",
    "## right plot\n",
    "right_y_axis_1 = axes[1].twinx()\n",
    "axes[1].scatter(bins_equalized,counts_equalized)\n",
    "axes[1].set_ylim(4000,7000)\n",
    "right_y_axis_1.set_ylim(0,1)\n",
    "right_y_axis_1.plot(bins_equalized, img_cdf_equalized, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's more, we've actually transformed the cumulative distribution function (CDF) of pixel values so that hte pixels are now optimally spaced across the entire pixel value range. This maximizes the global contrast of the image, which generally makes things easier to see.\n",
    "\n",
    "To read more about the math of histogram equalization (which is pleasantly intuitive), visit  \n",
    "https://en.wikipedia.org/wiki/Histogram_equalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `skimage.exposure.equalize_adapthist`\n",
    "\n",
    "As an alternative to `skimage.exposure.equalize_hist`, we can use `skimage.exposure.equalize_adapthist`, which performs the same process of spreading pixel intensity values evenly over the available range. However, whereas `skimage.exposure.equalize_hist` does this for the entire image at once, `skimage.exposure.equalize_adapthist` looks at each pixel within the context of a local neighborhood only. (By default, the neighborhoods are 1/8x1/8 of the image. This neighborhood size can be changed by setting the `kernal_size` argument in `skimage.exposure.equalize_adapthist` to the desired pixel value of the neighborhood. Give it a try.)\n",
    "\n",
    "`skimage.exposure.equalize_adapthist`'s main advantage over `skimage.exposure.equalize_hist` is that `skimage.exposure.equalize_adapthist` can adjust contrast locally, thus potentially giving better definition to a wider range of features from across the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import equalize_adapthist\n",
    "\n",
    "# compute histogram\n",
    "equalized_adapted_image = equalize_adapthist(phase_image, kernel_size=None)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16,8]\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"original phase image\")\n",
    "plt.imshow(phase_image, cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"equalized_adapted_image\")\n",
    "plt.imshow(equalized_adapted_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the original histogram with the histogram resulting from `skimage.exposure.equalize_adapthist`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute histograms\n",
    "(counts_phase, bins_phase) = histogram(phase_image)\n",
    "(counts_equalized, bins_equalized) = histogram(equalized_adapted_image)\n",
    "\n",
    "# compute cumulative distribution functions\n",
    "img_cdf_phase, bins_phase = exposure.cumulative_distribution(phase_image, 256)\n",
    "img_cdf_phase = img_cdf_phase\n",
    "img_cdf_equalized, bins_equalized = exposure.cumulative_distribution(equalized_adapted_image, 256)\n",
    "img_cdf_equalized = img_cdf_equalized\n",
    "\n",
    "# view histograms\n",
    "fig, axes = plt.subplots( nrows=1, ncols=2, figsize=(16,8) )\n",
    "\n",
    "## left plot\n",
    "right_y_axis_0 = axes[0].twinx()\n",
    "axes[0].scatter(bins_phase,counts_phase)\n",
    "#axes[0].plot(bins_phase, img_cdf_phase, 'r')\n",
    "right_y_axis_0.set_ylim(0,1)\n",
    "right_y_axis_0.plot(bins_phase, img_cdf_phase, 'r')\n",
    "\n",
    "## right plot\n",
    "right_y_axis_1 = axes[1].twinx()\n",
    "axes[1].scatter(bins_equalized,counts_equalized)\n",
    "#axes[1].set_ylim(4000,7000)\n",
    "right_y_axis_1.set_ylim(0,1)\n",
    "right_y_axis_1.plot(bins_equalized, img_cdf_equalized, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The net result of `skimage.exposure.equalize_adapthist` is to spread out really common pixel values somewhat, thereby increasing contrast among common pixel values, but not dramatically altering many values.\n",
    "\n",
    "Mathematical details can be found here:\n",
    "https://en.wikipedia.org/wiki/CLAHE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `skimage.exposure.rescale_intensity`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `skimage.exposure.adjust_gamma`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Thresholding & Threshold Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable (int) to hold a threshold value, which can be changed later to something more suitable.\n",
    "thresh = 200\n",
    "\n",
    "# Recall that relational (Boolean) expressions, such as 'smaller' (<), 'equal' (==) or 'greater or equal' (>=),\n",
    "# can be used with numpy arrays to directly assign the result to a new variable.\n",
    "mem = img > thresh\n",
    "\n",
    "# Check the dtype of your thresholded image - it should be boolean, meaning an array filled with 'True' and 'False',\n",
    "# where 'True' is the foreground (regions above the threshold) and 'False' is the background.\n",
    "print(mem.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10,7))\n",
    "ax[0].imshow(img, interpolation='none', cmap='gray')\n",
    "ax[1].imshow(mem, interpolation='none', cmap='gray')\n",
    "ax[0].set_title('Original Image')\n",
    "ax[1].set_title('Thresholded Membranes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can iterate through various threshold values to select something more appropriate. To do so interactively, we will utilize a class of interactive functions called 'widgets.' These are incredibly useful in exploratory data analysis to create simplified 'User Interfaces' (UIs) on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare widget\n",
    "from ipywidgets import interact\n",
    "@interact(thresh=(100,700,20))\n",
    "def select_threshold(thresh=200):\n",
    "    \n",
    "    # Thresholding\n",
    "    mem = img > thresh\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.imshow(mem, interpolation='none', cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we get tired of searching for the perfect threshold by hand (regardless of how cool our widget is). The scikit-image module `skimage.filters.thresholding` provides several threshold detection algorithms. One of the most popular ones \n",
    "is [Otsu's method](https://en.wikipedia.org/wiki/Otsu%27s_method). We can import the module and use it to automatically \n",
    "determine a threshold for the smoothed image. Then we can apply the threshold and visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from skimage.filters.thresholding import threshold_otsu\n",
    "\n",
    "# Calculate and apply threshold\n",
    "thresh = threshold_otsu(img)\n",
    "mem = img > thresh\n",
    "    \n",
    "# Visualization\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(mem, interpolation='none', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, what? Well, as it turns out, Otsu's method works best on smoothed images. Fortunately, scipy can help us there too. We can import the multi-dimensional image processing package from scipy and apply a Guassian filter to smooth the image before re-running Otsu's method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from skimage.filters.thresholding import threshold_otsu\n",
    "\n",
    "# Import the image processing package scipy.ndimage as ndi\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "# the gaussian_filter function expects a smoothing factor sigma, so we will arbitrarily define one (this can change later)\n",
    "sigma = 4\n",
    "img_smooth = ndi.filters.gaussian_filter(img, sigma)\n",
    "\n",
    "# Calculate and apply threshold\n",
    "thresh = threshold_otsu(img_smooth)\n",
    "Otsu = img_smooth > thresh\n",
    "    \n",
    "# Visualization\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(Otsu, interpolation='none', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example highlights a few important points: (1) Python (and the packages available for it) are very powerful in their ability to solve difficult problems quickly in very few lines of code; and (2) this can be dangerous - with great power comes great responsibility -> it is up to you to find these modules and understand what sort of data they are expecting.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering, Edge Detection, and Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dylan Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structuring Elements and Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our earlier section on thresholding, we quickly discovered the limitations of naive thresholding by a fixed value accross an entire image. Adaptive thresholding methods improve on this approach by varying the threshold for certain parts of the image.  \n",
    "\n",
    "One way of accomplishing this is known as adpative background subtraction. In this approach, we use a strong \"mean filter\" with a circular [structuring element](https://en.wikipedia.org/wiki/Structuring_element) to create the background image. Then, we use this background image for thresholding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a circular structuring element (SE) whose size depends on i\n",
    "i = 51\n",
    "SE = (np.mgrid[:i,:i][0] - np.floor(i/2))**2 + (np.mgrid[:i,:i][1] - np.floor(i/2))**2 <= np.floor(i/2)**2\n",
    "\n",
    "# Visualize the result\n",
    "plt.imshow(SE, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the background by running a mean filter over the image using the disc SE and assign the output to a new variable\n",
    "# Use the function 'skimage.filters.rank.mean'\n",
    "from skimage.filters import rank \n",
    "#bg = rank.mean(~np.uint8(img_smooth), selem=SE)\n",
    "bg = rank.mean(img_smooth, selem=SE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the resulting background image. \n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(bg, interpolation='none', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the Gaussian-smoothed original image against the background image using a relational expression\n",
    "mem = img_smooth > bg\n",
    "\n",
    "# Visualize the result against Otsu\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,15))\n",
    "ax[0].imshow(Otsu, interpolation='none', cmap='gray')\n",
    "ax[1].imshow(mem, interpolation='none', cmap='gray')\n",
    "ax[0].set_title('Otsu')\n",
    "ax[1].set_title('Adaptive')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving Masks with Binary Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is an improvment on our original results, our latest segmentation still leaves something to be desired. Let's see if we can improve the membrane segmentation with morphological operations. \n",
    "\n",
    "There are a number of operations available in the `ndimage` module that may be of use here (`ndi.binary_closing` or `ndi.binary_fill_holes` for example). Feel free to explore and see how the different functions affect the mask. Can you optimize the mask, for example by closing gaps?\n",
    "\n",
    "Also, note that the default SE for these functions is a square. Try to create another disc-shaped SE and see how that changes the outcome.\n",
    "\n",
    "In our first attempt, we are going to attempt to get rid of these speckles using binary hole filling. The documentation makes it clear that, for `ndi.binary_fill_holes` to work as intended, we need to invert the mask. The function `np.logical_not` or the corresponding operator '~' will help us here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mem_holefilled = np.logical_not(ndi.binary_fill_holes(np.logical_not(mem)))  # Long form\n",
    "mem_holefilled = ndi.binary_fill_holes(mem)  # Short form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New circular SE of appropriate size \n",
    "i = 17\n",
    "SE = (np.mgrid[:i,:i][0] - np.floor(i/2))**2 + (np.mgrid[:i,:i][1] - np.floor(i/2))**2 <= np.floor(i/2)**2\n",
    "\n",
    "# Sometimes, SE can introduce boundary artifact issues that can be solved with 'padding.' 'Padding' refers to the \n",
    "# extension of the image at the boundaries, in this case using a 'reflection' of the pixel values next to the boundary. \n",
    "# If morphological operations are done on the padded image, the boundary artifacts will occur in the padded region\n",
    "# outside the original image, which can simply be cropped out again at the end.\n",
    "pad_size = i+1\n",
    "mem_padded = np.pad(mem_holefilled, pad_size, mode='reflect')\n",
    "\n",
    "# Binary closing works well to round off the membranes and close gaps\n",
    "mem_final = ndi.binary_closing(mem_padded, structure=SE)\n",
    "\n",
    "# This slicing operation crops the padded image back to the original size\n",
    "mem_final = mem_final[pad_size:-pad_size, pad_size:-pad_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the final result\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,15))\n",
    "ax[0].imshow(mem_holefilled, interpolation='none', cmap='gray')\n",
    "ax[1].imshow(mem_final, interpolation='none', cmap='gray')\n",
    "ax[0].set_title('Hole Filled')\n",
    "ax[1].set_title('Final Membrane Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Watershed Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Output to Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NPZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs155",
   "language": "python",
   "name": "cs155"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
